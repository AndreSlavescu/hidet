# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
import pytest

import hidet


@pytest.mark.requires_cuda
def test_context():
    from hidet.lang import attrs, printf
    from hidet.lang.cuda.contexts import warp_groups
    from hidet.lang.cuda import threadIdx

    with hidet.script_module() as script_module:

        @hidet.script
        def func():
            attrs.func_kind = 'cuda_kernel'
            attrs.cuda.grid_dim = 1, 1, 1
            attrs.cuda.block_dim = 384, 1, 1

            # Use warp specialization to assign different roles to different warps
            with warp_groups([0]) as tid:
                # Producer code - first warp group (threads 0-127)
                if tid == 0:
                    printf("Producer warp group active\n")
                elif tid == 1:
                    printf("Producer warp group active as well\n")

            with warp_groups([1, 2]) as tid:
                # Consumer code - second warp group (threads 128-255)
                if tid == 0:
                    printf("Consumer warp group active\n")
                elif tid == 10:
                    printf("Thread 10 in consumer group\n")

            # Code executed by all threads
            if threadIdx.x == 0:
                printf("Test completed\n")

    func = script_module.build()
    func()


# The CUDA code generated by the above script is as follows,
# with the #include and __builtin_assume removed:

# ----------------------------------------------------------------
# static __global__ void __launch_bounds__(384) hidet_func() {
#   if ((int)threadIdx.x < 128) {
#     int32_t tid = ((int)threadIdx.x % 128);
#     if (tid == 0) {
#       printf("Producer warp group active\n");
#     } else {
#       if (tid == 1) {
#         printf("Producer warp group active as well\n");
#       }
#     }
#   }
#   if (128 <= (int)threadIdx.x) {
#     if (((int)threadIdx.x - 128) == 0) {
#       printf("Consumer warp group active\n");
#     } else {
#       if (((int)threadIdx.x - 128) == 10) {
#         printf("Thread 10 in consumer group\n");
#       }
#     }
#   }
#   if ((int)threadIdx.x == 0) {
#     printf("Test completed\n");
#   }
# }
#
# DLL void hidet_launch() {
#   hidet_func<<<dim3(1, 1, 1), dim3(384, 1, 1), 0, (cudaStream_t)get_cuda_stream()>>>();
#   {cudaError_t err = cudaGetLastError(); if (err != cudaSuccess) LOG(ERROR) << "CUDA error: " << cudaGetErrorString(err) << "\n";}
# }

if __name__ == '__main__':
    pytest.main([__file__])
